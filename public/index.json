[
{
	"uri": "/docker/rpi_install_docker/",
	"title": "Installation",
	"tags": [],
	"description": "Installation von Docker auf dem Raspberry Pi",
	"content": " So installiert man Docker auf dem Pi Docker installiert man auf dem Pi am besten über das offizell von Docker bereitgestellt Skript.\ncurl -sSL get.docker.com | sh  Anschliessend fügt man den Benutzer pi noch zur Gruppe docker hinzu.\nsudo usermod -aG docker pi sudo reboot  und aktiviert Docker als dienst.\nsudo systemctl enable docker sudo systemctl start docker  Wenn alles geklappt hat, prüft man noch die Version mit docker version und bekommt:\n'''sh pi@server4:~ $ docker version Client: Version: 18.05.0-ce API version: 1.37 Go version: go1.9.5 Git commit: f150324 Built: Wed May 9 22:24:36 2018 OS/Arch: linux/arm Experimental: false Orchestrator: swarm Server: Engine: Version: 18.05.0-ce API version: 1.37 (minimum version 1.12) Go version: go1.9.5 Git commit: f150324 Built: Wed May 9 22:20:37 2018 OS/Arch: linux/arm Experimental: false '''  Die aktuelle Releases findet man hier..\nErster Container Nun startet man seinen ersten Container mit:\nsudo docker run hello-world  Memory limit und CGroup probleme Bei einer frischen Installation von Debian bzw. Raspbian ist CGroup deaktiviert. Dadurch kommt es beim ausführen von docker info zu folgenden Warnungen.\n WARNING: No memory limit support WARNING: No kernel memory limit support  Außerdem wird bei docker stats für Memory immer 0 angezeigt.\nUm dies zu beheben sollte man CGroups aktivieren. Dazu einfach am ender der Datei /boot/cmdline.txt die Befehle cgroup_enable=cpuset cgroup_enable=memoryam Ende einfügen.\nsudo nano /boot/cmdline.txt  am Ende cgroup_enable=cpuset cgroup_enable=memory einfügen und mit STRG+O speichern. anschliessen den Pi neustarten.\nsudo reboot  QUELLE:\n Raspberry Pi 3 Model B Docker Schwarm Rechencluster | deutsch | 08. Januar 2017 How to install Docker on your Raspberry Pi | englisch | nicht so gut enabling cgroup memory  Fehm, Docker und Raspberry pi  VIDEO FHEM + Docker auf dem Raspberry Pi 3 | haus-automatisierung.com  "
},
{
	"uri": "/netzwerk/fritzbox/",
	"title": "FritzBox",
	"tags": [],
	"description": "FritzBox",
	"content": " Einstellungen zur Fritzbox Port 443 weiterleiten klappt nicht "
},
{
	"uri": "/netzwerk/",
	"title": "IT-Struktur",
	"tags": [],
	"description": "Übersicht des Datenfluss rund ums Web",
	"content": " Unter IT-Struktur wird dokumentiert, wie ich mein Netzwerk und den Datenfluss für die \u0026ldquo;öffentlich\u0026rdquo; erreichbaren Teile aufgebaut habe.\nFritzBox Ich habe einen ganz normalen Internet-Anschluss mit einer Fritzbox und ein paar Servern (meist RaspberryPi) auf der anderen Seite.\nDa sich die öffentliche IP-Adresse der Fritzbox täglich ändert, habe ich mich bei einem dynDNS anbieter angemeldet und bis so über blume.goip.de immer erreichbar. Wie man dies in der FritzBox einrichtet und welche Einstellung zum weiterleiten nötig sind habe ich hier beschrieben.\nRevers-Proxy Damit ich verschiedene Dienste oder Webseiten unter einer Domain erreichen kann, gehen alle Anfragen zunächst an einen nginx revers-proxy. Dieser leitet http Anfragen an verschiedene Server dahinter weiter. Im einfachsten fall bedeutet dass, zu Beispiel (www.blume.goip.de) eine schöne Famielen Hompage zeigt, (magic-brocoli.blume.goip.de) der Sohn seinen eigenen Blog schreiben kann und man unter (prv.blume.goip.de/urlaub2010/) die letzten Urlaubsfotos sienen Freunden zeigt.\nWie der Revers-Proxy eingerichtet wird seige ich hier.\n WebCluster WebCluster ist hier vieleicht etwas übertrieben, aber hier zeige ich einige Webserver und Dienste die ich verwende. Beschreibungen findet ihr hier:\n GitLab QNAP/NAS Web Blog Hausautomatisierung WebCluster mit Docker Swarm  "
},
{
	"uri": "/rpi/configuration/",
	"title": "Rpi einrichten",
	"tags": [],
	"description": "Grundkonfiguration des Pi",
	"content": " Grundkonfiguration Der erste Schritt für jeden Pi ist ersteinmal das Raspbian image auf eine SD-Karte zu spielen. Da es hierzu unzälige anleitungen gibt, sei es hier nur erwähnt und abgehakt.\nBetriebssystem auf SD-Karte spielen  Der zweite Schritt ist die raspi-config Erste einstellungen vornehmen\nsudo raspi-config  Passwort des users pi ändern  2 change user password  Dateisystem erweitern  9 Advanced Options A1 Expand filesstem  Boot-Option auswählen  3 Boot Options B1 Console  Sprach- und Zeiteinstellungen  #4 Internationalisation Options I1 Change Local [x] de_DE.UTF-8 UTF-8 aktivieren [ ] en_EN... deaktivieren de_DE als default I2 Change Timezone Europe -\u0026gt; Berlin  Hostname ändern  9 Advanced Options A2 Hostname   Zum Schluss lässtig, aber wichtig, der reboot.\nsudo reboot  Teil 2 - SSH-Schlüssel neu erstellen Da wir ein frisches Image verwendet haben und dies alle im Internet verwenden, ist auch der SSH fingerprint bei alles gleich. Also lassen wir diesen einmal neu erstellen\n:::shell sudo rm /etc/ssh/ssh_host_* sudo dpkg-reconfigure openssh-server sudo service ssh restart  Teil 3 - Software-Aktualisierung :::shell sudo apt update sudo apt upgrade sudo reboot  Teil 4 - RPI Firmware / Linux kernel aktualisieren Anzeige der aktuellen Linux version uname -a Anzeige der Hardware sudo cat /proc/device-tree/model Update\n:::shell sudo rpi-update sudo reboot  Sollte von jessy auf stretch gewechselt werden, so müssen die Paketquellen entsprechend angepasst werden. Siehe hier\nsudo nano /etc/apt/sources.list deb http://raspbian.raspberrypi.org/raspbian/ stretch main contrib non-free rpi  Teil 5 - Swap deaktivieren Swapping beim Raspberry pi deaktivieren \u0026gt; Speziell beim Raspberry Pi ist Swapping eigentlich kontraproduktiv. Swapping erhöht die Anzahl der Schreibzugriffe auf ein Speichermedium, auf dem sich der Swap-Speicher befindet. Das Betriebssystem und der Swap-Speicher befindet sich beim Raspberry Pi auf einer SD-Card, die nur eine begrenzte Anzahl an Schreibzugriffen verträgt, bevor einzelne Speicherzellen kaputt gehen. SD-Cards eignen sich überhaupt nicht zum Swapping. \u0026gt; Ein weiterer Grund auf Swapping zu verzichten ist die begrenzte Geschwindigkeit der SD-Card. Das macht das Swapping auf dem Raspberry Pi auch noch langsam. \u0026gt; Auch SSDs verkraften nur eine begrenzte Anzahl von Schreibzyklen. Auf eine SSD oder SD-Card zu swappen reduziert deren Lebensdauer und kann zu vorzeitigem Datenverlust führen\nZuerst stoppen des Swapping-Dienst\nsudo service dphys-swapfile stop  Anschließend prüfen wir, ob das Swapping abgeschaltet ist:\nfree -h  Wenn die Zeile \u0026ldquo;Swap\u0026rdquo; nur noch \u0026ldquo;0\u0026rdquo;-Werte aufweist, können wir den Swap-Dienst deaktivieren.\nsudo systemctl disable dphys-swapfile  Teil 6 - Logging in Arbeitsspeicher verschieben Häufiges schreiben auf die SD-Karte kann dies vorzeitig zertören und im schliommsten fall die Installation unbrauchbar machen. Dies ist mir auch schon einige male in den Jahren passiert. Das Raspberry scheint noch normal zu funktionieren und die Dienste und Programme laufen noch, doch lässt die SD-Karte keine schreibenden Zugriff mehr zu und alle Änderungen sind nach einem Neustart wieder futsch. Ein Teil im Raspberry der regelmäßig auf die SD-Karte schreibt sind die Dienste (Daemons). Alle abschalten wäre eine Möglichkeit, doch dann hat der Pi gar keine gunktion mehr :-). Eine andere Möglichkeit ist das Logging-Verzeichniss auf einen anderen Datenträger auszulagern. Ein Speicher der sehr viele schreib-Zugriff verträgt ist der RAM und mit einer virtuellen Festplatte im RAM lässt dich das Logging-Verzeichnis dorthin verschieben. Nun sind die Daten im RAM bekanntlicher weise nach einem Absturz/Neustart verloren und nun wären auch alle Logs verloren. Dies möchte man natürlich nicht und so erstellt man einen Dienst der regelmässig und beim ordendlichen herunterfahren/neustart alle Logs aus dem Arbeitsspeicher wieder auf die SD-Karte schreibt. Hierdurch wird der schreibzugriff aud die SD-Karte erheblich reduziert.\n{%alert%} In einigen Blogs und Seiten wird das Tool ramlog verwednet. Ich musste aber feststellen, dasss es mit der Debian Version Stretch nicht mehr funktioniert. Also ramlogund strechts sind nicht kompatiebel.{%alert%}\nAm einfachsten war für mich das tool log2ram, dessen isntallation auf dem Raspberry ich hier aufführe.\ncurl -Lo log2ram.tar.gz https://github.com/azlux/log2ram/archive/master.tar.gz tar xf log2ram.tar.gz cd log2ram-master chmod +x install.sh \u0026amp;\u0026amp; sudo ./install.sh cd .. rm -r log2ram-master sudo reboot  Quelle: https://github.com/azlux/log2ram\n"
},
{
	"uri": "/docker/container/rpi-hugo/",
	"title": "rpi-hugo",
	"tags": [],
	"description": "hugo docker image für raspberry pi",
	"content": " Docker Image mit Hugo v2.6 für Raspberry pi Unter [DockerHub] finden sich jede Menge gut images für Docker. Darunter finden sich auch einige, die bereits für den Raspberry übersetzt wurden, denn standartmäßig ist alles nur für Linux 64bit systeme gedacht. Die Gruppe hypriot hat schon seit einigen Jahren sich mit dem Thema Docker ung Raspberry auseinander gesetzt. So findet sich unter dockerhub/hypriot einige tolle repos.\nDarunter war auch ein repo für hypriot/rpi-hugo . Doch leider musste ich schnell feststellen, dass es zu alt ist und seit zwei Jaren auf Version 0.14 stehengeblieben ist. Zum Glück ist alles open-Source und so fand sich im Github reousitory alle nötigen dateien um ein neues image mit version v2.6 zu erstellen. Damit auch andere user etwas davon haben, habe ich es unter grembold/rpi-hugo wieder in DockerHub abgelegt.\nHier die wichtigsten befehle für das rpi-hugo repo:\nhugo webseite initialisieren mkdir myblog \u0026amp;\u0026amp; cd myblog docker run -rm -v $(pwd):/www grembold/rpi-hugo new site .  Mit dem ersten Befehl wird ein Verzeichniss erstellt, dindem später alle Dateien für die Webseite gesammelt werden. Mit dem zweiten Befehl wird das docker image ausgeführt und hugo erstellt im aktuellen Verzeichniss alle nöätigen Dateien und Ordner. Der Befehl -rm löscht den container nach dem ausführen gleich wieder. Mit -v $(pwd):/www wird das aktuelle Arbeitsverzeichniss als Volume in den docker container eingehängt. Die kryptische Anweisung $(pwd) ist dabei eine Umgebungsvariable von linux. Mit echo $(pwd) kann man sich den Inhalt anzeigen lassen.\nhugo webseite generieren docker run -rm -v $(pwd):/www grembold/rpi-hugo  Dieser Befehl generiert nun aus den Inhalten unter myblog/content/ die HTML-Seiten und legt alle benötigten daten unter myblog/public ab.\nhugo webseite testen docker run -d -p 1313:1313 -v $(pwd):/www hypriot/rpi-hugo server -b http://\u0026lt;ip-of-your-rpi\u0026gt;/ --bind=0.0.0.0 -w -D  Hiermit lässt sich die Webseite vorher einmal testen. Dabei werden durch die Option -D auch Seiten generiert die noch als Entwurf draft=truegekennzeichnet sind generiert.\n"
},
{
	"uri": "/docker/rpi_install_compose/",
	"title": "Installation docker-compose",
	"tags": [],
	"description": "Installation von Docker-Compose auf dem Raspberry Pi",
	"content": " Update (20185.08.09) Docker compose ist ein seperates projekt, das in python geschriben wurde. Seit docker Version 1.12 ist dies Funktionalität in die Docker-Engine integreirt worde. Link Seit docker verion 1.12 ist die intallation von docker-compose nicht mehr nötig und man kann äquivalent den befehl docker stackverweden.\nDer Leichte weg (nicht der Beste) Die Repositories von Raspian enthalten zum Glück inzwischen direkt eine docker-compose version. So kann mit dem gebräuchlichen Mittel apt direkt installiert werden\nsudo apt install -y docker-compose docker-compose version  Leider zeigt sich, dass man hier eine nicht ganz so frische Version erhält, so dass zur zweiten Variante zu raten ist.\nneue Version erstellen Sollte die Version aus dem Repository zu alt sein, lässt sich die neuste Version auch direkt auf dem Raspi compilieren.\nsudo apt update sudo apt install git mkdir docker-compose cd docker-compose git clone https://github.com/docker/compose.git cd compose/ git checkout release  Auf dem Raspberry pi 1 musste ich den zugrunde liegenden container änder, da es immer weider zur Fehlermeldung exit with non-zero code: 132gekommen ist. In der Datei Dockerfile.armhf habe ich gleich in der ersten Zeile\nFROM armhf/debian  durch\nFROM resin/rpi-raspbian  ersetzt.\nBuild and install docker-compose Eine docker-compose Binary zu erstellen ist recht einfach. Zuerst wird ein docker image erstellt, das die generierungs Umgebung enthält. Als zweites wird der container gestartet und die docker-comose Binary erstellt. Am Ende liegt die Binary im Unterverzeichnise dist\\.\ndocker build -t docker-compose:armhf -f Dockerfile.armhf . docker run --rm --entrypoint=\u0026quot;script/build/linux-entrypoint\u0026quot; -v $(pwd)/dist:/code/dist -v $(pwd)/.git:/code/.git \u0026quot;docker-compose:armhf\u0026quot;  Dies dauert gefühlt eine ewigkeit und kann durchaus 1 oder 2 Stunden dauern. Also erstmal aufstehen und etwas spazieren gehen. Ein bishcen frische Luft tut immer gut. Ist der ganze build durchgelaufen, befindet sich im Verzeichnis dist/ eine Biärdatei, die auf dein System kopiert wird.\nsudo cp dist/docker-compose-Linux-armv7l /usr/local/bin/docker-compose sudo chown root:root /usr/local/bin/docker-compose sudo chmod 0755 /usr/local/bin/docker-compose sudo reboot  Nun noch ein Test, ob sich die Mühe auch gelohnt hat ;-)\ndocker-compose version docker-compose version 1.11.0-rc1, build daed6db docker-py version: 2.0.2 CPython version: 2.7.13 OpenSSL version: OpenSSL 1.0.1t 3 May 2016  Dies kann man mit dem Releas aus GitHub vergleichen. docker/compose/release.\n Für ältere Versionen gibt es Hier eine gute Anleitung ein Build in einem Container anzustoßen.  "
},
{
	"uri": "/docker/swarm/",
	"title": "swarm",
	"tags": [],
	"description": "Swarm mit Raspberry Pi und Docker-Swarm",
	"content": " Swarm mit Raspberry Pi und Docker  Docker Swarm Mode auf einem Host | deutsch | 1. April 2018 | Ralf Geschke How to run a Raspberry Pi cluster with Docker Swarm  Kommandos auf mehreren pi\u0026rsquo;s ausführen\n Etwas auf mehreren pi\u0026rsquo;s installieren | deutsch | vom 08.01.2017 Raspberry Pi 3 Model B Docker Schwarm Rechencluster  Über den Befehl docker info kann man unter dem Punkt swarm sehen das dieser noch inactive ist.\nTeil 1 - Docker swarm initialisieren docker swarm init --advertise-addr 192.168.178.2  Um einen weiteren manager hinzuzufügen ruf man docker swarm join-token manager und befolgt die Anweisungen. Für einen worker entsprechend docker swarm join-token worker\ndocker swarm join --token SWMTKN-1-3xwnj7ptf9jsn95ehyljc1v4ul9rae69glpo1hhpp3ubirgam7-dcldyqvb7gjwlhgaf7qibhoo4 192.168.178.2:2377  Teil 2 - Test / Demo Docker Swarm Visualizer ist ein demo image zu anzeige von Services in einem docker swarm. Zum start:\n$docker service create \\ --name=viz \\ --publish=8080:8080/tcp \\ --constraint=node.role==manager \\ --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \\ alexellis2/visualizer-arm:latest  Dies wird sicher einige Minuten dauern, da das image erst heruntergeladen werden muss. In der zwischenzeit kann man auf einer zweiten Konsole den Status prüfen:\n```` sudo docker service ls ```  Bis der Service gestartet wurde wird dort REPLICAS value 0/1 stehen. Sobald der Service bereit ist (es wird 1\u0026frasl;1 angezeigt), ist die Webseite unter 192.168.178.5:8080 (irgend eine IP aus dem swarm) erreichbar\nAnsehen auf Docker Hub Quelle: https://howchoo.com/g/njy4zdm3mwy/how-to-run-a-raspberry-pi-cluster-with-docker-swarm engl. aber ok\nWo finde ich den swarm token docker swarm join-token manager  oder docker swarm join-token worker\n"
},
{
	"uri": "/netzwerk/nginx/",
	"title": "Revers-Proxy",
	"tags": [],
	"description": "NginX als Revers-Proxy einrichten",
	"content": "Damit ich verschiedene Dienste oder Webseiten unter einer Domain erreichen und zentral absichern kann, gehen alle Anfragen zunächst an einen revers-proxy. Dieser leitet http/https Anfragen an verschiedene Server dahinter weiter. Dies bedeutet, das zu Beispiel (www.blume.goip.de) an einen anderen Server weitergeleitet wird als (doc.blume.goip.de) oder (dev.blume.goip.de/gitlab/). Unter der URL blume.goip.de wird zum beispiel eine statische Webseite aufgerufen, die nur aus einer Seite besteht (Landingpage). Dies erledigt der WebServer 1 (WEB01). Unter der URL doc.blume.goip.de wird zum Beispiele diese Dokumentation aufgerufen, was wiederum Webserver 2 (WEB02) erledigt. Da so gut wie jedes Gerät oder Dienst im Heimischen Netzwerk heutzutage eine Webseite hat, könnte man damit auch den eigenen NAS, eine Hausautomatisierung oder die Webseite des Drucker aus dem Internet erreichbar machen.\n Let´s Encrypt Mit Let´s Encrypt ein Zertifikat erstellen\n  Server Ports und Namen Wie NginX entscheidet, welcher Server den Request bearbeiten soll.\n  Server Unterodrner (locations) Wie NginX entscheidet, welche location den Request bearbeiten soll.\n  HTTP Proxy HTTP-Anfragen an andere Server weiterleiten.\n  GitLab hinter nginx-Revers-Proxy HTTP-Anfragen an andere Server weiterleiten.\n   1 Zweite Web-Anwendung neben ownCloud/Nextcloud einrichten (am Beispiel WordPress) 2 nginx-Konfiguration: Owncloud im Unterordner des Webroot betreiben 3 Installation of WordPress in a subdirectory with nginx 4 Nginx als Reverse Proxy / Load Balancer  "
},
{
	"uri": "/rpi/ssh_key/",
	"title": "SSH und keys",
	"tags": [],
	"description": "Einrichten von Fernzugriff mit Schlüsseldateien",
	"content": " Secure Shell Mit Hilfe der Secure Shell (SSH) kann mann sich mit der Console des Raspberry Pi verbinden und Linux-Befehle auf dem pi ausführen.\nUm sich mit dem pi zu verbinden, ohne ein Passwort eingeben zu müssen, muss Authentifizierungs Schlüsselung anlegen und den System bekannt machen. Hierzu gibt es je Authentifizierung einen öffentlichen und einen privaten Schlüssel.Der öffentliche Schlüssel wird auf dem pi hinterlegt werden, wohingegen der private auf dem PC/Gerät verbleibt mit dem die Verbindung zu pi aufgebaut werden soll.\nZum generieren der Schlüssel gibt es verschiedene möglichkeiten Die einrichung erfolgt in zwei Schritten: 1. Schlüsselpaar erstellen 2. Schlüssel verteilen\nTeil 1 - Schlüssen mit puttygen erstelen. In der Programmsammlung von putty ist auch ein Key-Generator enthalten \u0026lsquo;puttygen.exe\u0026rsquo;. Mit diesem lässt sich auf einfache weise ein Schlüsselpaar erstellen. Also exe herunterladen und starten.  Verschlüsselungstyp auf: ECDSA und nistp384 stellen  Den Schlüsseltyp auswählen (ECDSA und nistp384) und auf Gererate klicken.  Maus im gelb markiertem Bereich bewegen!  Anschließend wird die erstellung der Schlüssel gestartet. Puttyken verwendet dabei die Mausbewegung als Zufallsgenerator. Daher muss der Mauszeiger im oberen bereich hin und her bewegt werden.\n Der obere Teil ist bereits der öffentliche Schlüssel für den Pi  Zum Schluss wird mit Save private key der private Schlüssel auf der Festplatte abgelegt. Es ist sehr hilfreich zuvor unter Key comment den Rechnernamen von dem die Verbindung aufgebaut werden soll einzutragen. Dies erleichter später die Unterscheidung der einzelnen Keys.\nIm oberen Teil sehen wird bereit die öffentlichen Schlüssel. Diesen kopiert man ab besten schonmal mit STR+C in die Zwischenablage, dann geht es mit dem zeiten Teil weiter.\nTeil 2 - Schlüssel verwenden Zunächst müssen wir uns auf dem pi klassisch mit Benutzername und Password anmelden. In unserem Fall melden wir auns also als pi an. Für diesen Benutzer müssen wir zunächst in seinem Homeverzeichniss einen Ordner für die erlaubten Schlüssel anlegen. Dies ist bei Raspian immer da versteckte Verzeichnis .ssh im Homeverzeichnes.\nmkdir -p ~/.ssh; chmod 700 ~/.ssh; touch ~/.ssh/authorized_keys; chmod 600 ~/.ssh/authorized_keys;  Beim letzten befehl muss der mittlere Teil \u0026ldquo;ecdsa-sha-nistp384 AAA\u0026hellip;==MeinPC\u0026rdquo; durch den öffentlichen Schlüssel aus puttyken ersetzt werden.\necho ecdsa-sha2-nistp384 AAAAE2VjZHNhLXNoYTItbmlzdHAzODQAAAAIbmlzdHAzODQAAABhBEKt1cRt+2PhzaqYT2fsCUv7gQKqGImPZtR7KpyE+KaJi+a4IHVL0nNshl4IcngTKG6aDG6H0w217/22YN9szO5cMWz6jUhVpZK6I3d/IX9fiT/gFri2UD3S8UQnFUw8GA== OlafsHomePC \u0026gt;\u0026gt; ~/.ssh/authorized_keys;  Nun Teilen wir noch putty mit, das es bei der Authentifizierung die private Schlüsseldatei auf unserem Rechner verwnden soll.\nTODO: Hier bild einfügen!!\n"
},
{
	"uri": "/netzwerk/nginx/letsencrypt/",
	"title": "Let´s Encrypt",
	"tags": [],
	"description": "Mit Let´s Encrypt ein Zertifikat erstellen",
	"content": " certbot installieren Wie das Docker image installiert wird habe ich bereits [hier]/docker/container/certbot/ beschrieben. Nun geht es darum ein Zertifikat für die eigene Domain zu erhalten.\nLet´s Encrypt Zertifikate für nginx installieren Erst wenn Sie sicher sind, dass alles klappt, entfernen Sie zuletzt die Option \u0026ndash;staging und wiederholen das Kommando nochmals zur Installation der endgültigen Zertifikate. Das Abrufen der Zertifikate läuft folgender massen ab: * Der eigene Webserver läuft und ist unter meineDomain:80 erreichbar. * Certbot erstell im www-Verzeichnis des Servers einen versteckten Ordner .well-known und einige Dateien * certbot prüft bei Let´s Encrypt, ob diese Dateien erreichbar sind. * ist dies erfolgreich, wird das Zertifikat unter /etc/letsencrypt/meineDomainabgelegt.\nDamit dies nun über das Docker Image funktioniert, müssen wir diesem zwei Verzeichnisse mitgeben. Das erste ist das WWW-Verzeichnis vom Webserver und das zweite ein Verzeichnis, indem der certbot die erstellten Zertifikate ablegen kann.\ndocker run --rm -v $CERTS_DIR:/etc/letsencrypt -p 80:80 --name certbot napnap75/rpi-certbot:latest certbot certonly --standalone --standalone-supported-challenges http-01 -t -n --agree-tos -m $EMAIL -d $HOST  Startet den certbot im \u0026ldquo;interaktiven\u0026rdquo; modus\ndocker run -it --rm \\ -v /home/pi/magic-broccoli/public:/var/www/ \\ -v /home/pi/nginx-proxy/certs:/etc/letsencrypt --name certbot bcecchinato/certbot-rpi \\ certonly --webroot -w /var/www/ -d blume.goip.de -d www.blume.goip.de -d doc.blume.goip.de  Zertifikat und Konfiguration testen HTTPS-Konfiguration noch über die Seite https://www.ssllabs.com prüfen lassen.\nZertifikate automatisch erneuern lassen \u0026quot;Volumes\u0026quot;: { \u0026quot;/etc/letsencrypt\u0026quot;: {}, \u0026quot;/sys/fs/cgroup\u0026quot;: {}, \u0026quot;/var/lib/letsencrypt\u0026quot;: {}  Zertifikate sichern Nun hat man es endlich geschafft und hält die eigenen TLS-Zertifikate in der Hand \u0026hellip; naja im Ordner. Doch Wo legt man diese hin, damit sie nicht verloren gehen. Sicher man kann sich ja jetzt jeder Zeit wieder neue machen und spätestens nach 3 Monaten ist dies auch nötig, doch möchte man das ein kleines certbot renewreicht und man nicht alles von vorn machen muss. Der Certbot hat alles nötige in ein Verzeichnis gepackt, dies müssten wir nur noch zippen und fertig, \u0026hellip; doch ganz so leicht ist es dann doch nicht. Die Zertifikate und ordner sind nur für den root lesbar und sollten es auch bleiben. Mit einem einfachen Zip würden die Benutzerrechte verloren gehen. Daher muss das Verzeichnis zunächst mit tar als eine Datei zusammenfasst werden und kann handlich komprimiert werden.\nsudo tar cf - certs/ | 7z a -si blume.goip.de.cert.20170908.7z  Das Entpacken eines solchen Archives läuft dann wieder in umgekehrter Reihenfolge ab (Achtung: Das Zielverzeichnis ZIELPFAD muss vorhanden sein!):\nsudo 7za x -so ERGEBNIS.tar.7z | tar xf - -C ZIELPFAD --numeric-owner  Quellen  https://letsencrypt.org/ https://certbot.eff.org/docs https://certbot.eff.org/#debianjessie-nginx https://kofler.info/lets-encrypt-zertifikate-fuer-web-und-mail-unter-ubuntu-16-04/ https://blog.doenselmann.com/nginx-und-lets-encrypt-auf-raspberry-pi/  "
},
{
	"uri": "/docker/container/certbot/",
	"title": "certbot-rpi",
	"tags": [],
	"description": "Raspberry Pi compatible Docker base image with Let´s Encrypt",
	"content": " Um sein aktuelles SSL-Zertifikat für meine Webseite zu erhalten, ist es am einfachsten auf ein vorhandenes Docker Image zurückzugreifen.\nWas ist Let´s Encrypt? Let´s Encrypt ist eine Zertifizierungsstelle die die erstellung von kostenlosen TLS-Zertifikaten anbietet. Ziel des Projektes ist es, jeden Internetdienst eine einfache Verschlüsselung anbieten kann. Dabei ist der Prozess zur erstellung des Zertifikats über den so genannten certbot automatisiert.\ncertbot-rpi on DockerHub certbot-rpi on GitHub\nHier eine kurze anleitung, wie das Docker Image verwendet wird.\nPull des Image docker pull pull bcecchinato/certbot-rpi  Aktuelle Version von Let´s Encrypt certbot abrufen docker run -it --rm bcecchinato/certbot-rpi --help  "
},
{
	"uri": "/docker/",
	"title": "docker",
	"tags": [],
	"description": "Projekte rund um das Thema Docker",
	"content": " Docker Docker ist eine Art Virualisierung, jedoch nicht von kompletten PCs wie bei den Virluellen Maschinen VMWare oder VirtualBox, sondern von Software und hieren Diensten. Dabei wird ein einzelnes Programm oder ein Dienst und alle dazu nötigen Unterprogramme zu einem Paket, dem so genannten Conteiner, zusammengeafasst und von anderen Programmen auf dem PC isoliert. Man spricht daher auch von Containervirtualisierung bzw. Anwendungsvirutalisierung.\nDie Verwendung dieser Conainer macht die In- und Deinstallation, sowie dier Verteilung und Bereitstellung für mehrere PCs sehr einfach.\nGlücklischer weise gibt es inzwischen Docker auch für den Raspian Pi, so dass mann Container, deren Verwaltung und sogar Verbünde meherere Pis zu einem Schwarm ausprobieren kann. Hat es nicht geklappt reciht ein remove und die Pi ist wieder sauber.\nWie man den Pi Installiert und erste Einstellungen vornimmt, habe ich bereits beschrieben.\nLINK: Einführung in docker\nInstallation und Projekte mit Docker  Installation Installation von Docker auf dem Raspberry Pi\n  Installation docker-compose Installation von Docker-Compose auf dem Raspberry Pi\n  swarm Swarm mit Raspberry Pi und Docker-Swarm\n  cluster Cluster mit Raspberry Pi und Docker und Kubernets\n  container Projekte rund um das Thema Docker\n  "
},
{
	"uri": "/docker/container/pi-hole/",
	"title": "pi-hole",
	"tags": [],
	"description": "Wie mann pi-hole als Docker auf dem pi startet",
	"content": " Pi-hole: Das schwarze loch für DNS anfragen https://www.nico-maas.de/?p=1525\nFür pi-hole gibt es zwar bereits ein docker image, doch auf meinem Raspberry Pi Model B der ersten Generation wollte docker und docker-compose nicht so recht laufen. Also habe ich dies zum Anlasss genmmen einmal eineneigenen Container zu erstellen.\nErstellen eies Dockerfiles für pi-hole Als erstes wird ein Ornder für die Dateien und das Docker image angelegt. Dann wird eine Datei mit dem Namen dockerfile erzeugt.\nmkdir pi-hole cd pi-hole touch dockerfile  Nach dem Anlegen der Datei wird diese mit einem Editor geöffnet. nano dockerfile\nDas Dockerfile Hier das listting für das dockerfile\nFROM resin/rpi-raspbian:stretch RUN apt-get update -qq; \\ apt-get upgrade -qq;  Docker image erzeugen Jetzt lassen wir docker das image bauen.\ndocker build -t pihole .  Nun das image als container starten\ndocker run -it pihole  Nun befinden wir uns innerhalb des containers. Mit\ncurl -sSL https://install.pi-hole.net | bash  wird die installation von pi-hole gestartet. Wenn wir mit einrichten und installation fertig sind, wird daraus wieder ein image gemacht.\ndocker commit pihole my/pihole  "
},
{
	"uri": "/docker/cluster/",
	"title": "cluster",
	"tags": [],
	"description": "Cluster mit Raspberry Pi und Docker und Kubernets",
	"content": " Cluster mit Raspberry Pi und Docker und Kubernets  admin magazin Kubernetes Cluster mit kubeadm  Kubernetes Cluster installation and configuration pi auf neusten stand bringen:\n::::ssh sudo apt-get update \u0026amp;\u0026amp; sudo apt-get upgrade sudo apt-get install -y apt-transport-https curl  installationspaket für kubernetz herungerladen\n:::: # Repository GPG Key installieren curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - # Kubernetes zu den Paketquellen hinzufügen echo \u0026quot;deb http://apt.kubernetes.io/ kubernetes-xenial main\u0026quot; | sudo tee -a /etc/apt/sources.list.d/k8s.list # Paketquellen aktualisieren sudo apt-get update # Installation sudo apt-get install kubeadm kubelet kubernetes-cni  Nach der Installation wird das Kubernetes-Cluster initialisiert:\n# Cluster initiieren sudo kubeadm init --skip-preflight-checks --pod-network-cidr=10.10.0.0/16 --apiserver-advertise-address=192.168.178.4  Warnung Leider habe ich die Installation abbrechen müssen, da ich die Fehlermeldung: CGROUPS_MEMORY: missing bekommen habe und nicht entfernen konnte. \u0026lt;div class=\u0026ldquo;alert alert-info\u0026rdquo;\nrole=\u0026ldquo;alert\u0026rdquo;\u0026gt;Deinstallieren\nSo, ist mal wieder schief gegangen, also alles wieder runter vom System :-(\n::: sudo apt remove kubeadm kubelet kubernetes-cni sudo apt autoremove sudo rm /etc/apt/sources.list.d/k8s.list sudo apt-get clean \u0026amp;\u0026amp; sudo apt update  \n "
},
{
	"uri": "/netzwerk/webserver/",
	"title": "WebServer",
	"tags": [],
	"description": "Einen Webserver mit NginX einrichten",
	"content": "Hugo Blog\nFhem\nSmartVisu\nWebCluster mit Docker Swarm\nMonitoren wie lange der eingene Server verfügbar war Beispiel trashserver.net UpTimeRobot\nWeb Server Survey\n(FreeFileSync)[https://www.freefilesync.org/] solte ich mir mal ansehen, um die Daten mit der NAS bazugleichen.\nSo, damit ich das nicht immer wieder vergesse. Im Repository dieser webseite sind die Themes als git submoldule eingebunden. Damit die aktuallisiert werden , muss folgenden ausgeführt werden\ngit submodule foreach git pull  Will man ein neues theme hinzufügen, som muss man mit $ git submodule add https://github.com/sethmacleod/docdock.git themes/docock in das eigene repository laden und anschließend in die initgit.sh integrieren $ git submodule init $ git submodule update\n"
},
{
	"uri": "/netzwerk/nginx/servername/",
	"title": "Server Ports und Namen",
	"tags": [],
	"description": "Wie NginX entscheidet, welcher Server den Request bearbeiten soll.",
	"content": " Virtuelle Server mit Namen Also NginX (gesprochen engine X) horcht auf verschiedene Port und bearbeitet die etsprechenden anfragen. Hier für nginx in einer Konfigurationsdatei mitgeteilt auf welche Ports er horchen und wie reagieren soll. Hier ein einfachen Beispiel, bei dem 3 mal auf port*:80 gehorcht wird:\nserver { listen 80; server_name example.org www.example.org; ... } server { listen 80; server_name example.net www.example.net; ... } server { listen 80; server_name example.com www.example.com; ... }  Hier sind 3 Server konfiguriert, die alle auf port 80 hören (listen 80;. Danach ermittelt nginx anhand des Feld \u0026ldquo;Host\u0026rdquo; aus dem HTTP Anfrage-Header zu welchem Server (server_name) die Anfrage groutet werden soll. Wenn dieser Wert zu keinem server namen passt oder die anfrage keine header feld enthält, so leitet nginx die Anfrage an seinen standard server für diesen port. In dieser Konfiguration an den ersten - was das Standardverhalten von nginx ist. Man kann mit dem parameter default_server in der listen Anweisung auch explizit festlegen, welcher der standard server sein soll.\nserver { listen 80 default_server; server_name example.net www.example.net; ... }  Beachte, dass der default_server Parameter von listenund nicht von server_nameist.\n So verhindern Sie Verarbeitungsanforderungen mit undefinierten Servernamen Wenn der HTTP-Request ohne \u0026ldquo;Host\u0026rdquo; header feld nicht erlaubt sein soll, so kann ein server angelegt werden , der diese anfragen fallen lässt.\nserver { listen 80; server_name \u0026quot;\u0026quot;; return 444; }  Hier ist der Server-Name auf einen leeren String gesetzt worden, so dass er mit HTTP-Request ohne \u0026ldquo;Host\u0026rdquo; header Feld übereinstimmt und ein nginx spezischer return code 444 zurückgegeben und die verbindung geschlossen wird.\n"
},
{
	"uri": "/rpi/",
	"title": "Raspberry Pi",
	"tags": [],
	"description": "Projekte rund um die kleine Himbeere",
	"content": " Projekte und Konfiguratoionen für die Himbeere Ein frisch erworbener Raspberry Pi muss erst einmal eingerichtet werden. Hierzu stöbert mann meistens im internet wie und wo mann die passende Einstellungen vornimmt. Und kommt irgendwann mal der zweite oder fünfte, so macht mann sich meist erneut auf die suche, oder geht doch mal eine Speicherkarte kaputt, kommt man schnell ins grübeln, was man damals alles machen musste.\nDie Raspberry Pi\u0026rsquo;s, die ich verwende laufen alle ohne Monitor oder Fernseher als kleine \u0026ldquo;Server\u0026rdquo; für meine Haus-IT oder den Garten, oder einfach nur zum spielen und lernen. Als betriebssystem verwende ich für alle das Raspbian, so dass sich die Anleitungen auch auf dieses beziehen. Fast alles habe ich mir nicht selber ausgetacht, sondern irgendwo im Netz gefunden und solange probiert, bis es ging. Dort wo ich die Adressen noch wusste, habe ich die jeweiligen Quelle aufgeführt. Dabei möchte ich ein paar hervorheben, die sich über die Jahre als sehr zuverlässig und verständlich erwisen haben.\n \u0026ldquo;www.elektronik-kompendium.de\u0026rdquo; Eine sehr Übersichtliche Seite in der viele wiechtige Themen verst#ndlich beschriben sind. Das toll ist auch, dass die meisten sachen sowohl mit Debian Jessy als auch Stretch getestet wurden und aktuell gehalten werden!   Rpi einrichten Grundkonfiguration des Pi\n  SSH und keys Einrichten von Fernzugriff mit Schlüsseldateien\n  RPi-Monitor Anzeigen des aktuellen Gesundheits-Zustand des Rpi\n  tricks Tipps und Trick im Umgang mit dem Pi\n  "
},
{
	"uri": "/rpi/rpimonitor/",
	"title": "RPi-Monitor",
	"tags": [],
	"description": "Anzeigen des aktuellen Gesundheits-Zustand des Rpi",
	"content": " Der aktuelle Zustand der eigenen Hinbeere lässt sich sehr schön über eine Web-Oberfläche anzeigen. Hierfür habe ich einige dieser Tools aufgeführt. Ausprobiert habe ich nur den RPI-Monitor, da er sehr einfach zu installieren war.\nRPi Monitor Das Tool von Xavier Berger lässt sich dank umfangreichen Installationsscript sehr leicht installieren. Dies ist auch das einzige Programm das ich sofort zum laufen gebracht habe. Eine gute Anleitung zu Installation findet man [hier].\nUPDATE(2018-05-26): RPI Monitor gibt es nun auch als Docker image!\nRPi-Monitor lässt sich über die beiden DAteien /etc/rpimonitor/data.confund /etc/rpimonitor/daemon.confparametrieren.\nContainer mit Log2Ram erweitern sudo apt install cron den rest wie unter RPi einrichten (https://github.com/ioBroker/ioBroker/wiki/Raspberry-Pi:-RPi-Monitor-installieren) und hier\n RPi-Homepage GitHub Soruce GitHub deb Pakete  Raspcontrol Raspcontrol ist ebenfalls ein web control center für den Raspberry pi. Das Programm ist schon durch einige Hände gegangen und wird vom wahrscheinlich ursprünglichen Entwickler Bioshox nicht mehr gepflegt. harmon25 hat das Projekt übernommen, doch der aktuellste Stand der Fork von hdijkema zu sein.\nDie Installation ist nicht ganz zu einfach wie beim RPi Monitor, lässt sich dennoch in 10 Minuten bewerkstelligen \u0026hellip; 2 Studen später \u0026hellip; dachte ich, aber irgendwie klappte es trotzdem nicht.\nPi Control Eine von Willy geschriebene Apache Aplikation als Gesundheitscheck des PI\n pi-control.de Willy\u0026rsquo;s Technik-Blog  RasPi Check RasPi Check ermöglicht die einfache und unkomplizierte Informationsabfrage eines Raspberry Pi vom Android Smartphone aus. Die App verwendet dabei sine SSH verbindung zum Pi. Hierbei handelt es sich also um eine Android App und keine WEbseite wie bei den andere Programmen.\n RasPi Check on Google play eidottermihi/rpicheck on GitHub  eZ Server Monitor ESM ist ein WebMonitor für alle möglichen Linux distributionen, u.a. auch für den RPi. Die Anleitung auf der Homepage ist etwas knapp gehalten.\n eZ Server Monitor  "
},
{
	"uri": "/rpi/tricks/",
	"title": "tricks",
	"tags": [],
	"description": "Tipps und Trick im Umgang mit dem Pi",
	"content": " Kommandos auf mehreren pi\u0026rsquo;s ausführen Hat man mit der Zeit mehr als einen Pi so möchte man manchmal Befehle auf allen ausführen, um beispielsweise alle auf Updates zu prüfen. Hierfür gibt es einen netten Trick:\nfor host in pi1 pi2 pi33 docker4; do ssh pi@$host sudo apt update; done  Quelle:\n Etwas auf mehreren pi\u0026rsquo;s installieren | deutsch | vom 08.01.2017  "
},
{
	"uri": "/netzwerk/nginx/location/",
	"title": "Server Unterodrner (locations)",
	"tags": [],
	"description": "Wie NginX entscheidet, welche location den Request bearbeiten soll.",
	"content": " Wie nginx etscheidet welches location/Subdiractorie den Request bearbeiten soll Schauen wir uns jetzt an, wie nginx einen Ord wählt, um eine Anfrage für eine typische, einfache PHP-Site zu verarbeiten:\nserver { listen 80; server_name example.org www.example.org; root /data/www; location / { index index.html index.php; } location ~* \\.(gif|jpg|png)$ { expires 30d; } location ~ \\.php$ { fastcgi_pass localhost:9000; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } }  Nginx sucht zuerst nach dem spezifischsten Präfix-Standort, der von Literal-Strings unabhängig von der aufgeführten Reihenfolge gegeben wird. In der oben aufgeführten Konfiguration ist die einzige Präfix-Position \u0026quot;/\u0026quot; und da sie mit jeder Anfrage übereinstimmt, wird sie als letzter Ausweg verwendet. Anschließend überprüft nginx die Standorte, die durch den regulären Ausdruck in der Konfigurationsdatei anhand der aufgeführten Reihenfolge. Der erste passende Ausdruck stoppt die Suche und nginx wird diesen Ort verwenden. Wenn kein regulärer Ausdruck mit einer Anforderung übereinstimmt, verwendet nginx die aktuellste Präfix-Stelle, die früher gefunden wurde.\nBeachten, dass location aller Typen nur den URI-Teil der Anforderungszeile ohne die Argumente testen. Dies geschieht, weil Argumente in der Abfragezeichenfolge auf mehrere Arten gegeben werden können, zum Beispiel:\n/index.php?user=john\u0026amp;page=1 /index.php?page=1\u0026amp;user=john  Außerdem kann jeder alles mögliche im Abfrage-String anfordern:\n/index.php?page=1\u0026amp;something+else\u0026amp;user=john  Schauen wir mal an, wie die Anfragen in der obigen Konfiguration verarbeitet werden.\n Eine Anforderung \u0026quot;/logo.gif\u0026quot; wird durch den Präfixort \u0026quot;/\u0026quot; zuerst und dann durch den regulären Ausdruck \u0026quot;\\.(gif|jpg|png)$\u0026quot; abgeglichen, daher wird er von der letzteren Stelle abgewickelt. Mit der Anweisung \u0026quot;root /data/www\u0026quot; wird die Anforderung der Datei /data/www/logo.gif zugeordnet und die Datei wird an den Client gesendet. Eine Anforderung \u0026quot;/index.php\u0026quot; wird auch durch den Präfixort \u0026quot;/\u0026quot; und dann durch den regulären Ausdruck \u0026quot;\\.php$\u0026quot; abgeglichen. Deshalb wird es von diesem Standort abgewickelt und die Anforderung an einen FastCGI-Server übergeben, der auf localhost:9000 hört. Die Fastcgi_param-Direktive setzt den FastCGI-Parameter SCRIPT_FILENAME auf \u0026quot;/data/www/index.php\u0026quot; und der FastCGI-Server führt die Datei aus. Die Variable $document_root ist gleich dem Wert der Root-Direktive und die Variable $fastcgi_script_name ist gleich der Request-URI, d.h. \u0026quot;/ index.php\u0026quot;. Eine Anforderung \u0026quot;/about.html\u0026quot; wird nur durch den Präfixort \u0026quot;/\u0026quot; abgeglichen, daher wird er an dieser Stelle abgewickelt. Mit der Anweisung \u0026quot;root /data/www\u0026quot; wird die Anforderung der Datei /data/www/about.html zugeordnet und die Datei wird an den Client gesendet. Die Handhabung einer Anfrage \u0026quot;/\u0026quot; ist komplexer. Es wird nur durch die Präfix-Position \u0026quot;/\u0026quot; abgeglichen, daher wird es von diesem Ort gehandhabt. Dann prüft die index-Direktive auf die Existenz von Indexdateien nach ihren Parametern und der \u0026quot;root /data/www\u0026quot;-Richtlinie. Wenn die Datei /data/www/index.html nicht existiert und die Datei /data/www/index.php existiert, führt die Richtlinie eine interne Weiterleitung zu \u0026quot;/index.php\u0026quot; durch und nginx durchsucht die Standorte erneut als wenn die Anfrage von einem Kunden gesendet wurde. Wie wir vorher gesehen haben, wird die umgeleitete Anfrage schließlich vom FastCGI-Server abgewickelt.  nginx forum https://forum.nginx.org/read.php?18,266984\n"
},
{
	"uri": "/netzwerk/nginx/proxy/",
	"title": "HTTP Proxy",
	"tags": [],
	"description": "HTTP-Anfragen an andere Server weiterleiten.",
	"content": " Das nginx-Modul ngx_http_proxy_module erlaubt es anfragen an andere Server weiterzuleiten.\nBeispielkonfiguration location / { proxy_pass http://localhost:8000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; }\n## proxy_pass proxy_pass legt das Protokoll und die Adresse eines Proxy-Servers und einer optionalen URI fest, an den ein Standort abgebildet/gemapped werden soll. Als Protokoll können \u0026ldquo;http\u0026rdquo; oder \u0026ldquo;https\u0026rdquo; angegeben werden. Die Adresse kann als Domain Name oder IP-Adresse angegeben werden und ein optionaler Port:\nproxy_pass http://localhost:8000/uri/;  oder als UNIX-Domain-Socket-Pfad, der nach dem Wort \u0026ldquo;Unix\u0026rdquo; angegeben und in Doppelpunkte eingeschlossen ist:\nproxy_pass http://unix:/tmp/backend.socket:/uri/;  Wenn ein Domain-Name auf mehrere Adressen auflöst, werden alle in einer Round-Robin-Methode verwendet. Zusätzlich kann eine Adresse als Servergruppe angegeben werden.\nParameterwert kann Variablen enthalten. In diesem Fall wird, wenn eine Adresse als Domänenname angegeben wird, der Name unter den beschriebenen Servergruppen durchsucht und, falls nicht gefunden, mit einem Resolver ermittelt.\nEin Anforderungs-URI wird wie folgt an den Server übergeben:\n Wenn die Proxy_pass-Direktive mit einem URI angegeben wird, wird dann, wenn eine Anforderung an den Server übergeben wird, der Teil eines normalisierten Anforderungs-URI, der mit dem Standort übereinstimmt, durch einen URI ersetzt, der in der Anweisung angegeben ist:\nlocation /name/ { proxy_pass http://127.0.0.1/remote/; }\n Wenn proxy_pass ohne einen URI angegeben wird, wird der Anforderungs-URI an den Server in der gleichen Form übermittelt, wie er von einem Client gesendet wird, wenn die ursprüngliche Anforderung verarbeitet wird, oder die vollständige normalisierte Anforderungs-URI wird bei der Verarbeitung des geänderten URI übergeben:\nlocation /some/path/ { proxy_pass http://127.0.0.1; }\n  proxy_set_header Ermöglicht das Neudefinieren oder Anfügen von Feldern an den an den Proxy-Server übergebenen Anforderungs-Header. Der Wert kann Text, Variablen und deren Kombinationen enthalten. Diese Richtlinien werden von der vorherigen Ebene geerbt, wenn und nur wenn keine proxy_set_header-Direktiven auf der aktuellen Ebene definiert sind. Standardmäßig sind nur zwei Felder neu definiert:\nproxy_set_header Host $proxy_host; proxy_set_header Connection close;  Wenn das Caching aktiviert ist, werden die Header-Felder \u0026ldquo;If-Modified-Since\u0026rdquo;, \u0026ldquo;If-Unmodified-Since\u0026rdquo;, \u0026ldquo;If-None-Match\u0026rdquo;, \u0026ldquo;If-Match\u0026rdquo;, \u0026ldquo;Range\u0026rdquo; und \u0026ldquo;If-Range\u0026rdquo; von der ursprüngliche Anforderung nicht an den Proxy-Server weitergegeben.\nEin unverändertes \u0026ldquo;Host\u0026rdquo; -Anforderungs-Header-Feld kann wie folgt übergeben werden:\nproxy_set_header Host $http_host;  Wenn dieses Feld jedoch nicht in einem Client-Request-Header vorhanden ist, wird nichts übergeben. In einem solchen Fall ist es besser, die Variable $ host zu verwenden - ihr Wert entspricht dem Servernamen im Feld \u0026ldquo;Host\u0026rdquo; -Anforderungsheader oder dem primären Servernamen, falls dieses Feld nicht vorhanden ist:\nproxy_set_header Host $host;  Zusätzlich kann der Servername zusammen mit dem Port des Proxy-Servers übergeben werden:\nproxy_set_header Host $host:$proxy_port;  Wenn der Wert eines Header-Feldes eine leere Zeichenfolge ist, wird dieses Feld nicht an einen Proxy-Server weitergegeben:\nproxy_set_header Accept-Encoding \u0026quot;\u0026quot;;  proxy_redirect Setzt den Text, der in den Headerfeldern \u0026ldquo;Location\u0026rdquo; und \u0026ldquo;Refresh\u0026rdquo; geändert werden soll. Angenommen, ein Proxy-Server hat das Header-Feld \u0026quot;Location: http://localhost:8000/two/some/uri/\u0026quot; zurückgegeben. Die Direktive\nproxy_redirect http://localhost:8000/two/ http://frontend/one/;  wird diese Zeichenfolge auf \u0026quot;Location: http://frontend/one/some/uri/\u0026quot; umschreiben.\nEin Servername kann in der Ersatzzeichenfolge weggelassen werden:\nproxy_redirect http://localhost:8000/two/ /;  dann wird der Name des primären Servers und der Port, falls abweichend von 80, eingefügt.\nDie Standardersetzung, die durch den default angegeben wird, verwendet die Parameter der location- und proxy_pass-Direktiven. Daher sind die beiden folgenden Konfigurationen äquivalent:\nlocation /one/ { proxy_pass http://upstream:port/two/; proxy_redirect default; location /one/ { proxy_pass http://upstream:port/two/; proxy_redirect http://upstream:port/two/ /one/;  Der Standardparameter ist nicht zulässig, wenn proxy_pass mit Variablen angegeben wird.\nEin Ersatzstring kann Variablen enthalten:\nproxy_redirect http://localhost:8000/ http://$host:$server_port/;  Eine Umleitung kann auch (1.1.11) Variablen enthalten:\nproxy_redirect http: // $ proxy_host: 8000 / /; Die Richtlinie kann mit regulären Ausdrücken (1.1.11) angegeben werden. In diesem Fall sollte die Umleitung entweder mit dem \u0026ldquo;~\u0026rdquo; - Symbol für eine Groß- / Kleinschreibung oder mit den \u0026ldquo;~ *\u0026rdquo; - Symbolen für die Groß- / Kleinschreibung beginnen. Der reguläre Ausdruck kann benannte und positionale Erfassungen enthalten, und der Ersatz kann sie verweisen:\nproxy_redirect ~^(http://[^:]+):\\d+(/.+)$ $1$2; proxy_redirect ~*/user/([^/]+)/(.+)$ http://$1.example.com/$2;  Es könnte mehrere proxy_redirect Richtlinien geben:\nproxy_redirect default; proxy_redirect http://localhost:8000/ /; proxy_redirect http://www.example.com/ /;  Der Aus-Parameter hebt den Effekt aller proxy_redirect-Direktiven auf der aktuellen Ebene auf:\nproxy_redirect aus; proxy_redirect default; proxy_redirect http://localhost:8000/ /; proxy_redirect http://www.example.com/ /;  Mit dieser Anweisung ist es auch möglich, Hostnamen zu relativen Weiterleitungen hinzuzufügen, die von einem Proxy-Server ausgegeben werden:\nproxy_redirect / /;  "
},
{
	"uri": "/netzwerk/nginx/gitlab_domain_subfolder/",
	"title": "GitLab hinter nginx-Revers-Proxy",
	"tags": [],
	"description": "HTTP-Anfragen an andere Server weiterleiten.",
	"content": " Um GitLab unter einer relativen URL verwenden zu können  Install GitLab under a relative URL  Diese Anleitung beschreibt wie GitLab unter einer relativen URL verwendet werden kann, nur bei \u0026ldquo;installation from sourve\u0026rdquo;. Wenn alternativ zur installation ein Omnibus package verwendet wurde, sind die schritte unterschiedlich.\nNutze diese Anleitung zusammen mit dem installation guid, wenn du GitLAb das erste mal installiert.\n  GitLab Docker mit relativen URL Dieses Docker Image wird auch von der QNAP Containerstation verwendet.  "
},
{
	"uri": "/docker/container/",
	"title": "container",
	"tags": [],
	"description": "Projekte rund um das Thema Docker",
	"content": " Meine Container  rpi-hugo hugo docker image für raspberry pi\n  certbot-rpi Raspberry Pi compatible Docker base image with Let´s Encrypt\n  pi-hole Wie mann pi-hole als Docker auf dem pi startet\n  "
},
{
	"uri": "/impressum/",
	"title": "Impressum",
	"tags": [],
	"description": "Verantwortlich für dieses Angebot gemäß § 5 TMG / § 55 RStV",
	"content": " Impressum Verantwortlich für dieses Angebot gemäß § 5 TMG / § 55 RStV: Olaf Blume Franz-Schubert-Str. 2\n21365 Adendorf\nemail: olaf-petersen @ gmx.de\nHaftung für Links Unser Angebot enthält Links zu externen Webseiten Dritter, auf deren Inhalte wir keinen Einfluss haben. Deshalb können wir für diese fremden Inhalte auch keine Gewähr übernehmen. Für die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf mögliche Rechtsverstöße überprüft. Rechtswidrige Inhalte waren zum Zeitpunkt der Verlinkung nicht erkennbar.\nEine permanente inhaltliche Kontrolle der verlinkten Seiten ist jedoch ohne konkrete Anhaltspunkte einer Rechtsverletzung nicht zumutbar. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.\n"
},
{
	"uri": "/links/",
	"title": "Links",
	"tags": [],
	"description": "Interessante Links aus dem Internet",
	"content": " Heiter bis Wolkig \u0026ldquo;Der hybride IT-Infrastruktur Blog\u0026rdquo;. Deutsche Seite mit einigen Artikeln zu Docker.\n USB im Docker Docker Autostart nach System-Reboot git learn  "
},
{
	"uri": "/",
	"title": "DocDock für Blume",
	"tags": [],
	"description": "DocDock für Blume",
	"content": " Olafs Dokumentation für PC und Pastelprojekte Auf dieser Seite möchte ich Anleitungen für verschiedene Bastelprojekte von mir dokumentieren. Ziel der Bastelprojekte ist es, mich im Bereich der Informationsverarbeitung, Netzsicherheit und Linux weiterzubilden (bloß nicht den Anschluss verlieren) und dabei auch etwas Spaß am Probieren und tüfteln zu haben. Vieleicht nutze ich aber auch einen Teil als blog, um den zeitlichen Fortschritt zu dokumentieren und später daraus Tutorials oder Anleitungen zu erstellen. mal sehen\u0026hellip;\nDokumentations Webseite Diese Dokumentation ist eine mit hugo statisch generierte Webseite. Enddeckt habe ich es auf dem Blog von hypriot, in dem viel über Docker und Raspberry Pi erklärt wird und es schien mir für den Einstieg bestens geeignet zu sein. Weitere dieser \u0026ldquo;static site generators\u0026rdquo; und warum sie für einfache Webseiten oder Blogs super eignen sind, findet ihr unter staticgen.com.\n"
},
{
	"uri": "/_header/",
	"title": "header",
	"tags": [],
	"description": "",
	"content": "Blume Dokumentation\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]